---
title: "Introduction to the lineSampler Package"
author: "Drew Schmidt"
date: "`r Sys.Date()`"
output:
  html_document:
    fig_caption: true
    toc: true
    number_sections: true
    css: include/custom.css
    highlight: kate
bibliography: include/lineSampler.bib
csl: "include/ieee.csl"
vignette: >
  %\VignetteIndexEntry{Introduction to the lineSampler Package}
  %\VignetteEngine{knitr::rmarkdown}
---


# Introduction

**lineSampler** [[@lineSampler]] is a simple R package for reading random subsamples of flat text files by line in a reasonably efficient manner.  We do so by sampling as the input file is scanned and randomly choosing whether or not to dump the current line to an external temporary file.  This  temporary file is then read back into R.  For (aggressive)  downsampling, this is a very effective strategy; for resampling, you are much better off reading the full dataset into memory.
 
The basic function performs the sampling/reading in a single pass. There is an alternative version which allows for an exact amount to be subsampled via reservoir sampling, but this version requires 2 passes through the data.  The heavy lifting is done entirely in C. 

This package, including the underlying C library, is licensed under the permissive 2-clause BSD license.  The original idea was inspired by Eduardo Arino de la Rubia's **fast_sample** [[@fast_sample]].


## Installation

You can install the stable version from CRAN using the usual `install.packages()`:

```r
install.packages("lineSampler")
```

The development version is maintained on GitHub.  You can install this version using the `devtools` package:

```r
devtools::install_github("wrathematics/lineSampler")
```



# Using the Package

At its most basic, you can use just the `sample_csv()` for csv files:

```r
lineSampler::sample_csv(file)
```

and `sample_lines()` for reading unstructured lines (as `readLines()`):

```r
lineSampler::sample_lines(file)
```

Optionally, you can control the proportion at which lines are randomly selected to be read in.


## Other Readers

To keep external dependencies to a minimum, only the base R `read.csv()` and `readLines()` are directly supported.  If you wish to use other readers like `fread()` from **data.table** [[@datatable]] or `read_csv()` from **readr** [[@readr]], you can use the `sample_file_prob()` and `sample_file_exact()` functions.  See the `sample_csv()` source code for inspiration.





# Details

## Benchmarks

The package should perform very well, provided the number of lines sampled is relatively small.  For a small (in absolute, not relative terms) number of lines, the total time spent should be dominated by scanning through the file.

For example, consider the file:

```r
file <- "/tmp/big.csv"

memuse::Sys.filesize(file)
## 742.736 MiB

wc(file)
# file:   /tmp/big.csv 
# Nletters: 766639674
# Nwords:   12174948
# Nlines:   12174948 
```

We can read in approximately 0.1% of the input file quite quickly:

```r
system.time({
  small <- sample_csv(file, .001)
})
##  user  system elapsed 
## 0.920   0.104   1.022 
```

Compare this to the time spent reading the entire file:

```r
system.time({
  full <- read.csv(file)
})
##    user  system elapsed 
## 216.776   3.412 220.038 
```

Note the difference in file sizes:

```r
dim(small)
## 12174     6
memuse::memuse(small)
## 432.703 KiB

dim(full)
## 12174947  6
memuse::memuse(full)
## 417.998 MiB
```

Also notice that the in-memory file size of the full file times the proportion of lines read in is roughly the size of the downsampled file:

```r
memuse::memuse(ret)*.001
## 428.030 KiB
```

Obviously the **lineSampler** strategy is valuable only for aggressive downsampling, and not resampling.


## How It Works

For `sample_file_prob()` which samples lines at a given proportion, the input file is scanned, line-by-line, and lines are randomly placed into a temporary file at the given proportion. This requires one pass through the file. In the "exact" version, a reservoir sampler is used to determine which lines will be read, and then pass through the input file and dumping lines to the temporary file as necessary (i.e., if that line number was chosen by the sampler). In each case, R's `read.csv()` or `readLines()` is used to read the temp file into R.  

The package attempts to be reasonably efficient, with the underlying I/O handled by very ad hoc C code via `fgets()`. The exact reader requires 2 passes through the file: one to get the line counts, then one to sample.  The proportion version only requires one pass through the file. 

On Linux (and possibly other OS's), your file may get cached on the first read, so the second read might be comparatively cheap. But for very large files (which shouldn't be csv anyway!), downsampling with the inexact version and a p of .001 or smaller should be more than sufficient.





# Legal

&copy; 2016 Drew Schmidt.

This manual is licensed under a [Creative Commons CC-BY license](http://creativecommons.org/licenses/by/4.0/).

This manual may be incorrect or out-of-date.  The authors assume no responsibility for errors or omissions, or for damages resulting from the use of the information contained herein.

<script language="JavaScript" src="include/headers.js"></script>
